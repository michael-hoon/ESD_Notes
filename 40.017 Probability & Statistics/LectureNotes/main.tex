\documentclass{article}
\usepackage{LectureNotes}
\usepackage{mathtools}

\setstretch{1.2}

\begin{comment}
\geometry{
    textheight=9in,
    textwidth=5.5in,
    top=1in,
    headheight=12pt,
    headsep=25pt,
    footskip=30pt
}
\end{comment}


\geometry
{
    a4paper,
    total={170mm,257mm},
    left=20mm,
    top=20mm,
}


% ------------------------------------------------------------------------------

\begin{document}

% ------------------------------------------------------------------------------
% Cover Page and ToC
% ------------------------------------------------------------------------------

\title{ \normalsize \textsc{}
		\\ [2.0cm]
		\HRule{1.5pt} \\
		\LARGE \textbf{\uppercase{40.017 Probability \& Statistics}
		\HRule{2.0pt} \\ [0.6cm] \LARGE{Lecture Notes} \vspace*{10\baselineskip}}
		}
\date{\today}
\author{\textbf{Michael Hoon}}

\maketitle
\newpage

\tableofcontents
\newpage

% ------------------------------------------------------------------------------


\section{Set Theory}

\subsection{Sample Spaces}

The mathematical framework for probability is built around \textit{sets}. The \textit{sample space} $S$ of an experiment is the set of all possible outcomes of the experiment. An \textit{event} $A$ is a subset of $S$, and we say that $A$ occurred if the actual outcome is in $A$.  

\subsection{Naive Definition of Probability}

Let $A$ be an event for an experiment with a finite sample space $S$. A naive probability of $A$ is 

\begin{equation}
    \mathbb{P}_{\text{naive}}(A) = \frac{|A|}{|S|} = \frac{\text{number of outcomes favorable to A}}{\text{total number of outcomes}}
\end{equation}

\noindent In general, the result about complements always holds:

\begin{equation*}
    \mathbb{P}_{\text{naive}}(A^{c}) = \frac{|A^{c}|}{|S|} = \frac{|S| - |A|}{|S|} = 1- \frac{|A|}{|S|} = 1 - \mathbb{P}_{\text{naive}}(A)
\end{equation*}

An important factor about the naive definition is that it is restrictive in requiring $S$ to be finite. 

\subsection{General Definition of Probability}

\begin{definition}
    A probability space consists of a sample space $S$ and a probability function $P$ which takes an event $A \subseteq S$ as input and returns $P(A)$, where $P(A) \in \mathbb{R}, \; P(A) \in [0, 1]$. The function must satisfy the following axioms:

    \begin{enumerate}
        \item $\mathbb{P}(\emptyset) = 1, \; \mathbb{P}(S) = 1$ 
        \item $\mathbb{P}(A) \geq 0$
        \item If $A_{1}, A_{2}, \dots$ are \textbf{disjoint events}, then: \begin{equation*}
            \mathbb{P} \left( \bigcup_{j=1}^{\infty} \right) = \sum_{j=1}^{\infty} \mathbb{P}(A_j)
        \end{equation*}
        \noindent Disjoint events are \textbf{mutually exclusive} (i.e. $A_i \cap A_j = \emptyset \; \forall \; i \neq j$).
    \end{enumerate}
\end{definition}

\subsubsection{Properties of Probability}
\begin{theorem}

Probability has the following properties, for any events $A$ and $B$: 

\begin{enumerate}
    \item $\mathbb{P}(A^{c}) = 1 - \mathbb{P}(A)$
    \item If $A \subseteq B$, then $\mathbb{P}(A) \leq \mathbb{P}(B)$
    \item $\mathbb{P}(A \cup B) = \mathbb{P}(A) + \mathbb{P} (B) - \mathbb{P}(A \cap B)$ 
\end{enumerate}
\end{theorem}

\subsubsection{Inclusion-Exclusion Principle}

For any events $A_{1}, \dots A_n$, 

\begin{equation}
    \mathbb{P}\left( \bigcup_{i=1}^{n} A_i \right) = \sum_{i} \mathbb{P}(A_i) - \sum_{i<j} \mathbb{P}(A_i \cap A_j) + \sum_{i<j<k} \mathbb{P}(A_i \cap A_j \cap A_k) - \dots + (-1)^{n+1} \mathbb{P}(A_{1} \cap \dots \cap A_n)
\end{equation}

\noindent For $n=2$, we have a nicer result:

\begin{equation*}
    \mathbb{P}(A_{1} \cup A_{2}) = \mathbb{P}(A_{1}) + \mathbb{P}(A_{2}) - \mathbb{P}(A_{1} \cap A_{2})
\end{equation*}

\subsection{Conditional Probability}

\begin{definition}
    If $A$ and $B$ are events with $\mathbb{P}(B) > 0$, then the \textit{conditional probability} of $A$ given $B$, denoted by $\mathbb{P}(A \mid B)$ is defined as: 

    \begin{equation*}
        \mathbb{P}(A | B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}
    \end{equation*}
\end{definition}

\noindent Here $A$ is the event whose uncertainty we want to update, and $B$ is the evidence we observe. $\mathbb{P}(A)$ is the \textit{prior} probability of $A$ and $\mathbb{P}(A | B)$ is the \textit{posterior} probability of $A$. (For any event $A$, $\mathbb{P}(A|A) = \frac{\mathbb{P}(A \cap A)}{\mathbb{P}(A)}$).




\section{Derangement}

A derangement is a permutation of the elements of a set in which no element appears in its original position. We use $D_n$ to denote the number of derangements of $n$ distinct objects. 

\subsection{Counting Derangements}
We consider the number of ways in which $n$ hats ($h_{1}, \dots, h_n$) can be returned to $n$ people ($P_{1}, \dots, P_n$) such that no hat makes it back to its owner. \\

We obtain the recursive formula:

\begin{equation}\label{1-eq: derangement}
    D_n = (n-1)(D_{n-1} + D_{n-2}), \; \forall \; n \geq 2
\end{equation}

\noindent With the initial conditions $D_{1} = 0$ and $D_{2} = 1$, we can use the formula to recursively compute $D_n$ for any $n$. \\

\noindent There are various other expressions for $D_n$, equivalent to formula \ref{1-eq: derangement}:

\begin{equation}\label{1-eq: derangement sum}
    D_n = n! \sum_{i=0}^{n} \frac{(-1)^{i}}{i!}, \; \forall \; n \geq 0
\end{equation}

\subsubsection{Limiting Growth}
From Equation \ref{1-eq: derangement sum}, and the taylor series expansion for $e$:

\begin{equation}
    e^{x} = \sum_{i=0}^{\infty} \frac{x^{i}}{i!} 
\end{equation}

\noindent we substitute $x=-1$ and obtain the limiting value as $n \to \infty$:

\begin{equation*}
    \lim_{n \to \infty} \frac{D_n}{n!} = \lim_{n \to \infty} \sum_{i=0}^{n} \frac{(-1)^{i}}{i!} = e^{-1} \approx 0.367879\dots
\end{equation*}

\noindent This is the limit of the probability that a randomly selected permutation of a large number of objects is a derangement. The probability converges to this limit extremely quickly as $n$ increases, which is why $D_n$ is the nearest integer to $\frac{n!}{e}$. 

\section{Discrete Random Variables}

We formally define a random variable:

\begin{definition}
    Given an experiment with sample space $S$, a \textit{random variable} (r.v.) is a function from the sample space $S$ to the real numbers $\mathbb{R}$. It is common to denote random variables by capital letters. 
\end{definition}

\noindent Thus, a random variable $X$ assigns a numerical value $X(s)$ to each possible outcome $s$ of the experiment. The randomness comes from the fact that we have a random experiment (with Probabilities described by the probability function $P$); the mapping itself is deterministic. \\

There are two main types of random variables used in practice: \textit{discrete} and \textit{continuous} r.v.s. 

\begin{definition}
    A random variable $X$ is said to be \textit{discrete} if there is a finite list of values $a_{1}, a_{2}, \dots, a_n$ or an infinite list of values $a_{1}, a_{2}, \dots$ such that $\mathbb{P}(X = a_j \; \text{for some }j) = 1$. If $X$ is a discrete r.v., then the finite or countably infinite set of values $x$ such that $P(X = x) > 0$ is called the \textit{support} of $X$.  
\end{definition}







\subsection{Binomial}

\subsection{Hypergeometric}

If we have an urn filled with $w$ white and $b$ black balls, then drawing $n$ balls out of the urn \textit{with replacement} yields a $\text{Binom}(n, \frac{w}{(w+b)})$. If we instead sample \textit{without replacement}, then the number of white balls follow a \textbf{Hypergeometric} distribution. 

\begin{theorem}
    If $X \sim \text{hypgeo}(n, j, k)$, then the PMF of $X$ is:

    \begin{equation*}
        \mathbb{P}(X = x) = \frac{\binom{j}{x}\binom{k}{n-x}}{\binom{j+k}{n}}
    \end{equation*}
    \noindent $\forall x \in \mathbb{Z}$ satisfying $0\leq x \leq n$ and $0\leq n-x \leq j$, and $P(X=x) = 0$ otherwise. 
\end{theorem}

\noindent If $j$ and $k$ are large compared to $n$, then selection without replacement can be approximated by selection with replacement. In that case, the hypergeometric RV $X \sim \text{hypgeo}(n,j,k)$ can be approximated by a binomial RV $Y \sim \text{binomial}(n,p)$, where $p := \frac{j}{j+k}$ is the probability of selecting a black marble. \\

\noindent We can also write $X$ as the sum of (dependent) Bernoulli random variables:

\begin{equation*}
    X = X_{1} + X_{2} + \dots + X_n
\end{equation*}

where each $X_i$ equals 1 if the $i$th selected marble is black, and 0 otherwise. 


\subsubsection{Hypergeometric Symmetry}

\begin{theorem}
    The hypergeo$(w,b,n)$ and hypergeo$(n,w+b-n,w)$ distributions are identical. 
\end{theorem}

\noindent The proof follows from swapping the two sets of tags in the Hypergeometric story (white/black balls in urn) \footnote[3]{The binomial and hypergeometric distributions are often confused. Note that in Binomial distributions, the Bernoulli trials are \textbf{independent}. The Bernoulli trials in Hypergeometric distribution are \textbf{dependent}, since the sampling is done \textit{without replacement}.}. 


\subsection{Geometric}

\subsection{Negative Binomial}

In a sequence of independent Bernoulli trials with success probability $p$, if $X$ is the number of failures before the $r$th success, then $X$ is said to have the Negative Binomial distribution with parameters $r$ and $p$, denoted $X \sim \text{NBin}(r,p)$. \\ 

\noindent Both the Binomial and Negative Binomial distributions are based on independent Bernoulli trials; they differ in the \textit{stopping rule} and in what they are counting. The Negative Binomial counts the \textbf{number of failures until a fixed number of successes}. 

\begin{theorem}
    If $X \sim \text{NBin}(r,p)$, then the PMF of $X$ is 

    \begin{equation}
        P(X=x) = \binom{x-1}{n-1} (1-p)^{x-n}p^{n}, \; \forall \; x\geq n 
    \end{equation}
\end{theorem}





\section{Law of Large numbers}
Assume that we have i.i.d. $X_{1}, X_{2}, \dots$ with finite mean $\mu$ and finite variance $\sigma^{2}$. Let $\bar{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i$.

\begin{definition}
    The (Weak) Law of Large Numbers (LLN) says that as $n$ grows, the sample mean $\bar{X}_n$ converges to the true mean $\mu$. Mathematically, 
    \begin{equation}
        \forall \epsilon > 0, \; \mathbb{P}(|\bar{X}_n - \mu < \epsilon) = 1, \; \text{as} \; n \to \infty 
    \end{equation}

    \noindent For any positive margin $\epsilon$, as $n$ gets arbitrarily large, the probability that $\bar{X}_n$ is within $\epsilon$ of $\mu$ approaches 1. 
\end{definition}

\noindent Note that the LLN does not contradict the fact that a coin is memoryless (in the repeated coin toss experiment). The LLN states that the proportion of Heads converges to $\frac{1}{2}$, but this does not imply that after a long string of Heads, the coin is "due" for a Tails to "\textit{balance things out}". Rather, the convergence takes place through \textit{swamping}: past tosses are swamped by the infinitely many tosses that are yet to come.  

\subsection{Inequalities}
The inequalities in this section provide bounds on the probability of an r.v. taking on an 'extreme' value in the right or left rail of a distribution. 

\subsubsection{Markov's Inequality}
\begin{definition}
    Let $X$ be any random variable that takes only non-negative values, that is, $\mathbb{P}(X < 0) = 0$. Then for any constant $a >0$, we have: 
    \begin{equation}
        \mathbb{P}(X \geq a) \leq \frac{\mathbb{E}(X)}{a}
    \end{equation}
\end{definition}

\noindent For an intuitive interpretation, let $X$ be the income of a randomly selected individual from a population. Taking $a = \mathbb{E}(X)$, Markov's Inequality says that $\mathbb{P(X \geq 2 \mathbb{E}(X)) \leq \frac{1}{2}}$. i.e., it is impossible for more than half the population to make at least twice the average income. 

\subsubsection{Chebyshev's Inequality}
Gives general bounds for the probability of being $k$ standard deviations (SD) away from the mean. 

\begin{definition}
    Let $Y$ be any random variable with mean $\mu < \infty$ and variance $\sigma^{2} > 0$. Then for any constant $k>0$, we have: 
    \begin{equation}
        \mathbb{P}(|Y-\mu| \geq k\sigma) \leq \frac{1}{k^{2}}
    \end{equation} 
\end{definition}

\section{Central Limit Theorem}
Let $X_{1}, X_{2}, \dots$ be i.i.d. with mean $\mu$ and variance $\sigma^{2}$. 

\begin{definition}
    The CLT states that for large $n$, the distribution of $\bar{X}_n$ after standardisation approaches a standard Normal distribution. By standardisation, we mean that we subtract $\mu$, the mean of $\bar{X}_n$, and divide by $\frac{\sigma}{\sqrt{n}}$, the standard deviation of $\bar{X}_n$. 
    \begin{equation}
        \lim_{n \to \infty} \mathbb{P}(\frac{\bar{X}_n - \mu}{\frac{\sigma}{\sqrt{n}}} \leq x) = \Phi(x)    
    \end{equation}
    \noindent which is the cdf of the standard normal. Informally, when $n$ is large ($\geq 30$), then $\bar{X}_n$ and $\sum_{i=1}^{n} X_i$ can each be approximated by a normal RV with the same mean and variance; the actual distribution of $X_i$ becomes irrelevant:
    \begin{equation*}
        \bar{X}_n \approx N(\mu, \frac{\sigma^{2}}{n}), \qquad \sum_{i=1}^{n} X_i \approx N(n\mu, n\sigma^{2})
    \end{equation*}
\end{definition}

\section{Moments}

\subsection{Interpreting Moments}
\begin{definition}
    Let $X$ be an r.v. with mean $\mu$ and variance $\sigma^{2}$. For any positive integer $n$, the $n^{\text{th}}$ moment of $X$ is $\mathbb{E}(X^{n})$, the $n^{\text{th}}$ central moment is $\mathbb{E}((X - \mu)^{n})$. 
\end{definition}

\noindent In particular, the mean is the first moment and the variance is the second central moment. 

\subsection{Moment Generating Functions}
A moment generating function, as its name suggests, is a generating function that encodes the \textbf{moments} of a distribution. Starting with an infinite sequence ($a_{0}, a_{1}, a_{2}, \dots$), we 'condense' or 'store' it as a single function $g$, the generating function of the sequence:

\begin{equation*}
    \sum_{n=0}^{\infty} a_n \frac{t^{n}}{n!} \coloneqq g(t) 
\end{equation*}

\begin{definition}
    When we take $a_n = \mathbb{E}(X^{n})$, the resulting generating function is known as the \textbf{moment generating function (MGF)} of $X$, and is denoted by $M_X(t)$. \\ 

    \noindent The MGF of $X$ can be computed as an expected value: 

    % \begin{equation}
    %     M_X (t) = \sum_{n=0}^{\infty} \mathbb{E(X^{n}) \frac{t^{n}}{n!} = \sum_{n=0}^{\infty} \mathbb{E}\left(\frac{t^{n}}{n!}\right) \\
    %     = \mathbb{E}\left(\sum_{n=1}^{\infty}\frac{(tX)^{n}}{n!}\right) \\
    %     = \mathbb{E}(e^{tX})
    % \end{equation}
\end{definition}

\noindent Note that $M_X (0) = 1$ for any valid MGF. 

\subsection{Formulas \& Theorems}
Some important formulas for the MGF of $X$:

\begin{equation}
    \boxed{M_X (t) = \mathbb{E} (e^{tX})} 
\end{equation}

\noindent where if $X$ is \textbf{discrete} with pmf $f$, then 

\begin{equation}
    M_X (t) = \sum_{all x_i} e^{t x_i} f(x_i) 
\end{equation}

\noindent and if $X$ is \textbf{continuous} with pdf $f$, then 

\begin{equation}
    M_X (t) = \int_{-\infty}^{\infty} e^{tx} f(x) \, \mathrm{d}x
\end{equation}

\begin{theorem}
    Given the MGF of $X$, we can get the $n^{\text{th}}$ moment of $X$ by evaluating the $n^{\text{th}}$ derivative of the MGF at 0: 

    \begin{equation}
        \boxed{\mathbb{E}(X^{n}) = M_X^{(N)} (0)} 
    \end{equation}
\end{theorem}

\begin{theorem}
    If $X$ and $Y$ are independent, then the MGF of $X + Y$ is the product of the individual MGFs:
    \begin{equation}
        M_{X+Y} (t) = M_X(t)M_Y(t)
    \end{equation}
    \noindent This is true because if $X$ and $Y$ are independent, then $\mathbb{E}(e^{t(X+Y)}) = \mathbb{E}(e^{tX})\mathbb{E}(e^{tY})$ 
\end{theorem}

\begin{theorem}
    If two random variables have the same MGF, then they have the same distribution (same cdf, equivalently, same pdf or pmf) \footnote{For this to apply, the MGF needs to exist in an open interval around $t=0$}.
\end{theorem}

\subsection{Examples (Discrete)}

\subsubsection{Binomial MGF}
We have $f(x) = \binom{n}{x} p^{x} (1-p)^{n-x}$. The MGF can be found by:

\begin{align}
    M_{X} (t) &= \sum_{x=0}^{n} \binom{n}{x} (\underbrace{e^{t}p}_{a})^{x} (\underbrace{1-p}_b)^{n-x} \\ \nonumber
    &= (e^{t}p + 1-p)^{n}
\end{align}

\noindent by using the fact that 

\begin{equation*}
    \sum_{x} \binom{n}{x} a^{x} b^{n-x} = (a + b)^{n} 
\end{equation*}

\noindent and from which we can obtain $\mathbb{E}(X) = M'_X(0) = n \overbrace{(e^{t}p + 1 - p)^{n-1} \cdot e^{t}p \mid_{t=0}}^{p} = np$

\subsubsection{Poisson MGF}
For a Poisson r.v., where $X \sim \text{Poisson}(\lambda)$ We have $f(x) = e^{-\lambda} \frac{\lambda^{x}}{x!}$. Then,

\begin{align}
    M_X (t) &= \sum_{x=0}^{\infty} e^{tx} e^{-\lambda} \frac{\lambda^{x}}{x!} \\ \nonumber
    &= e^{-\lambda} \sum_{x=0}^{\infty} \frac{(e^{t}\lambda)^{x}}{x!} \\ \nonumber
    &= e^{-\lambda} e^{e^{t}\lambda} \\ \nonumber
    &= e^{e^{t}\lambda - \lambda} \\ \nonumber
    &= e^{\lambda(e^{t} - 1)}
\end{align}

\noindent We can now find:

\begin{equation*}
    M'_X (t) = e^{\lambda(e^{t} - 1)}(\lambda e^{t})
\end{equation*}

\noindent and therefore 

\begin{equation*}
    M'_X (0) = e^{0} (\lambda e^{0}) = \lambda
\end{equation*}

\subsection{Examples (Continuous)}

\subsubsection{Standard Normal}

If $Z \sim \mathcal{N}(0,1)$ is a standard normal r.v., then $f(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^{2}}{2}}$. For continuous distributions, we need to use the infinite integral:

\begin{align}
    M_Z(t) &= \mathbb{E}(e^{tZ}) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{tx} e^{-\frac{x^{2}}{2}} \, \mathrm{d}x \\ 
    &=  
\end{align}






\newpage 

\section*{References}

Some references used in these notes: \\ 

Introduction to Probability, Joe Blitzstein \& Jessica Hwang. 

\end{document}